{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = \"Hassan\"\n",
    "print(f\"My Grandson is {person}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd UPDATED_NLP_COURSE/00-Python-Text-Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd 00-Python-Text-Basics"
   ]
  },
  {
   "cell_type": "code",
>>>>>>> ca9a7cba51f67ef83b120e66b68307ba926614a6
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "My Grandson is Hassan\n"
     ]
    }
   ],
   "source": [
    "person = \"Hassan\"\n",
    "print(f\"My Grandson is {person}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n"
     ]
    }
   ],
   "source": [
    "!cd UPDATED_NLP_COURSE/00-Python-Text-Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n"
     ]
    }
   ],
   "source": [
    "!cd 00-Python-Text-Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pwd' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
=======
      "/home/hassan/Documents\n"
>>>>>>> ca9a7cba51f67ef83b120e66b68307ba926614a6
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PyPDF2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MUHAMM~1.FAR\\AppData\\Local\\Temp/ipykernel_15704/2053148783.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mPyPDF2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmy_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/home/hassan/Documents/UPDATED_NLP_COURSE/00-Python-Text-Basics/US_Declaration.pdf\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'PyPDF2'"
     ]
    }
   ],
=======
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
>>>>>>> ca9a7cba51f67ef83b120e66b68307ba926614a6
   "source": [
    "import PyPDF2\n",
    "my_file = open(\"/home/hassan/Documents/UPDATED_NLP_COURSE/00-Python-Text-Basics/US_Declaration.pdf\", mode='rb')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> ca9a7cba51f67ef83b120e66b68307ba926614a6
   "source": [
    "pdf_reader = PyPDF2.PdfFileReader(my_file)\n",
    "pdf_reader.numPages"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Declaration of IndependenceIN CONGRESS, July 4, 1776. The unanimous Declaration of the thirteen united States of America, When in the Course of human events, it becomes necessary for one people to dissolve the\n",
      "political bands which have connected them with another, and to assume among the powers of the\n",
      "earth, the separate and equal station to which the Laws of Nature and of Nature's God entitle\n",
      "\n",
      "them, a decent respect to the opinions of mankind requires that they should declare the causes\n",
      "\n",
      "which impel them to the separation. \n",
      "We hold these truths to be self-evident, that all men are created equal, that they are endowed by\n",
      "\n",
      "their Creator with certain unalienable Rights, that among these are Life, Liberty and the pursuit\n",
      "of Happiness.ŠThat to secure these rights, Governments are instituted among Men, deriving\n",
      "\n",
      "their just powers from the consent of the governed,ŠThat whenever any Form of Government\n",
      "becomes destructive of these ends, it is the Right of the People to alter or to abolish it, and to\n",
      "institute new Government, laying its foundation on such principles and organizing its powers in\n",
      "such form, as to them shall seem most likely to effect their Safety and Happiness. Prudence,\n",
      "\n",
      "indeed, will dictate that Governments long established should not be changed for light and\n",
      "transient causes; and accordingly all experience hath shewn, that mankind are more disposed to\n",
      "suffer, while evils are sufferable, than to right themselves by abolishing the forms to which they\n",
      "\n",
      "are accustomed. But when a long train of abuses and usurpations, pursuing invariably the same\n",
      "Object evinces a design to reduce them under absolute Despotism, it is their right, it is their duty,\n",
      "to throw off such Government, and to provide new Guards for their future security.ŠSuch has\n",
      "been the patient sufferance of these Colonies; and such is now the necessity which constrains\n",
      "\n",
      "them to alter their former Systems of Government. The history of the present King of Great\n",
      "\n",
      "Britain is a history of repeated injuries and usurpations, all having in direct object the\n",
      "establishment of an absolute Tyranny over these States. To prove this, let Facts be submitted to a\n",
      "candid world. He has refused his Assent to Laws, the most wholesome and necessary for the\n",
      "public good.\n",
      "He has forbidden his Governors to pass Laws of immediate and pressing\n",
      "importance, unless suspended in their operation till his Assent should be obtained;\n",
      "and when so suspended, he has utterly neglected to attend to them.\n",
      "\n",
      "He has refused to pass other Laws for the accommodation of large districts of\n",
      "people, unless those people would relinquish the right of Representation in the\n",
      "Legislature, a right inestimable to them and formidable to tyrants only. \n",
      "\n",
      "He has called together legislative bodies at places unusual, uncomfortable, and distant\n",
      "from the depository of their public Records, for the sole purpose of fatiguing them into\n",
      "compliance with his measures.\n",
      "\n"
     ]
    }
   ],
>>>>>>> ca9a7cba51f67ef83b120e66b68307ba926614a6
   "source": [
    "page_one = pdf_reader.getPage(0)\n",
    "print(page_one.extractText())"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 15,
>>>>>>> ca9a7cba51f67ef83b120e66b68307ba926614a6
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file.close()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> ca9a7cba51f67ef83b120e66b68307ba926614a6
   "source": [
    "f = open(\"/home/hassan/Documents/UPDATED_NLP_COURSE/00-Python-Text-Basics/US_Declaration.pdf\", mode='rb')\n",
    "pdf_reader = PyPDF2.PdfFileReader(f)\n",
    "\n",
    "pdf_reader.numPages\n",
    "\n",
    "#pdf_writer = PyPDF2.PdfFileWriter()\n",
    "#pdf_writer.addPage(first_page)\n",
    "\n",
    "#pdf_out = open(\"New_Pdf.pdf\", mode='wb')\n",
    "#pdf_writer.write(pdf_out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
<<<<<<< HEAD
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/hassan/Documents/UPDATED_NLP_COURSE/New_Pdf.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MUHAMM~1.FAR\\AppData\\Local\\Temp/ipykernel_15704/181397811.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/home/hassan/Documents/UPDATED_NLP_COURSE/New_Pdf.pdf\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpdf_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPyPDF2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPdfFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpdf_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumPages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#first_page = pdf_reader.getPage(0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/hassan/Documents/UPDATED_NLP_COURSE/New_Pdf.pdf'"
     ]
=======
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
>>>>>>> ca9a7cba51f67ef83b120e66b68307ba926614a6
    }
   ],
   "source": [
    "l = open(\"/home/hassan/Documents/UPDATED_NLP_COURSE/New_Pdf.pdf\", mode='rb')\n",
    "pdf_reader = PyPDF2.PdfFileReader(l)\n",
    "\n",
    "pdf_reader.numPages\n",
    "#first_page = pdf_reader.getPage(0)\n",
    "#page_one_text = first_page.extractText()\n",
    "#page_one_text"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Number is 123\n"
     ]
    }
   ],
>>>>>>> ca9a7cba51f67ef83b120e66b68307ba926614a6
   "source": [
    "d = {'a': 123, 'b': 456}\n",
    "print(f\"My Number is {d['a']}\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 19,
>>>>>>> ca9a7cba51f67ef83b120e66b68307ba926614a6
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My list is 5\n"
     ]
    }
   ],
   "source": [
    "my_list =[0,1,2,3,4,5,6,7,8,9]\n",
    "print(f\"My list is {my_list[5]}\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 20,
>>>>>>> ca9a7cba51f67ef83b120e66b68307ba926614a6
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author Topic Pages\n",
      "Farooq NLP 456\n",
      "Hassan KG 1\n"
     ]
    }
   ],
   "source": [
    "library =[('Author','Topic','Pages'),('Farooq','NLP',456),('Hassan','KG',1)]\n",
    "\n",
    "for author, topic, pages in library:\n",
    "    print(f\"{author} {topic} {pages}\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 21,
>>>>>>> ca9a7cba51f67ef83b120e66b68307ba926614a6
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Writing text.txt\n"
=======
      "Overwriting text.txt\n"
>>>>>>> ca9a7cba51f67ef83b120e66b68307ba926614a6
     ]
    }
   ],
   "source": [
    "%%writefile text.txt\n",
    "This is my frist text file and I will retrieve it later.\n",
    "You should not open it and if you did then you will denied the access."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 22,
>>>>>>> ca9a7cba51f67ef83b120e66b68307ba926614a6
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "'d:\\\\Python\\\\Machine-Learning-Exercises'"
      ]
     },
     "execution_count": 9,
=======
       "'/home/hassan/Documents'"
      ]
     },
     "execution_count": 22,
>>>>>>> ca9a7cba51f67ef83b120e66b68307ba926614a6
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 23,
>>>>>>> ca9a7cba51f67ef83b120e66b68307ba926614a6
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%cd/UPDATED_NLP_COURSE` not found.\n"
     ]
    }
   ],
   "source": [
    "%cd/UPDATED_NLP_COURSE\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n"
     ]
    }
   ],
=======
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
>>>>>>> ca9a7cba51f67ef83b120e66b68307ba926614a6
   "source": [
    "!cd UPDATED_NLP_COURSE"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 25,
>>>>>>> ca9a7cba51f67ef83b120e66b68307ba926614a6
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[WinError 2] The system cannot find the file specified: 'UPDATED_NLP_COURSE'\n",
      "d:\\Python\\Machine-Learning-Exercises\n"
=======
      "/home/hassan/Documents/UPDATED_NLP_COURSE\n"
>>>>>>> ca9a7cba51f67ef83b120e66b68307ba926614a6
     ]
    }
   ],
   "source": [
    "%cd UPDATED_NLP_COURSE"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 26,
>>>>>>> ca9a7cba51f67ef83b120e66b68307ba926614a6
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      " Volume in drive D has no label.\n",
      " Volume Serial Number is 50EE-A07E\n",
      "\n",
      " Directory of d:\\Python\\Machine-Learning-Exercises\n",
      "\n",
      "08/03/2022  02:16 pm    <DIR>          .\n",
      "08/03/2022  02:16 pm    <DIR>          ..\n",
      "15/02/2022  10:46 am               823 Hello.ipynb\n",
      "08/03/2022  02:15 pm            11,501 NLP_Basics.ipynb\n",
      "01/02/2022  03:43 pm                79 README.md\n",
      "08/03/2022  02:16 pm               130 text.txt\n",
      "               4 File(s)         12,533 bytes\n",
      "               2 Dir(s)  150,813,691,904 bytes free\n"
=======
      "\u001b[0m\u001b[01;34m00-Python-Text-Basics\u001b[0m/                New_Pdf.pdf\n",
      "\u001b[01;34m01-NLP-Python-Basics\u001b[0m/                 Pierian_Data_Logo.png\n",
      "\u001b[01;34m02-Parts-of-Speech-Tagging\u001b[0m/           pipeline1.png\n",
      "\u001b[01;34m03-Text-Classification\u001b[0m/               stemming1.png\n",
      "\u001b[01;34m04-Semantics-and-Sentiment-Analysis\u001b[0m/  stemming2.png\n",
      "\u001b[01;34m05-Topic-Modeling\u001b[0m/                    \u001b[01;34mTextFiles\u001b[0m/\n",
      "\u001b[01;34m06-Deep-Learning\u001b[0m/                     text.txt\n",
      "\u001b[01;34m07-BONUS-NOTEBOOKS-NO-VIDEOS\u001b[0m/         tokenization.png\n",
      "\u001b[01;34mmoviereviews\u001b[0m/\n"
>>>>>>> ca9a7cba51f67ef83b120e66b68307ba926614a6
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 27,
>>>>>>> ca9a7cba51f67ef83b120e66b68307ba926614a6
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[WinError 3] The system cannot find the path specified: 'UPDATED_NLP_COURSE/00-Python-Text-Basics'\n",
      "d:\\Python\\Machine-Learning-Exercises\n"
=======
      "[Errno 2] No such file or directory: 'UPDATED_NLP_COURSE/00-Python-Text-Basics'\n",
      "/home/hassan/Documents/UPDATED_NLP_COURSE\n"
>>>>>>> ca9a7cba51f67ef83b120e66b68307ba926614a6
     ]
    }
   ],
   "source": [
    "%cd UPDATED_NLP_COURSE/00-Python-Text-Basics"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 28,
>>>>>>> ca9a7cba51f67ef83b120e66b68307ba926614a6
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "'d:\\\\Python\\\\Machine-Learning-Exercises'"
      ]
     },
     "execution_count": 15,
=======
       "'/home/hassan/Documents/UPDATED_NLP_COURSE'"
      ]
     },
     "execution_count": 28,
>>>>>>> ca9a7cba51f67ef83b120e66b68307ba926614a6
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 29,
>>>>>>> ca9a7cba51f67ef83b120e66b68307ba926614a6
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test.txt'",
     "output_type": "error",
     "traceback": [
<<<<<<< HEAD
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MUHAMM~1.FAR\\AppData\\Local\\Temp/ipykernel_15704/1832818705.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmyfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test.txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmyfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test.txt'"
=======
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/hassan/Documents/NLP_Basics.ipynb Cell 22'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/hassan/Documents/NLP_Basics.ipynb#ch0000021?line=0'>1</a>\u001b[0m myfile \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mtest.txt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hassan/Documents/NLP_Basics.ipynb#ch0000021?line=1'>2</a>\u001b[0m myfile\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test.txt'"
>>>>>>> ca9a7cba51f67ef83b120e66b68307ba926614a6
     ]
    }
   ],
   "source": [
    "myfile = open(\"test.txt\")\n",
    "myfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = myfile.read()\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.seek(0)\n",
    "myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = open('test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.seek(0)\n",
    "mylines = myfile.readlines()\n",
    "for lines in mylines:\n",
    "    print(lines.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = open(\"word.txt\",\"w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext.write(\"This my first attempt in writing a text \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext.seek(0)\n",
    "mytext.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = open(\"word.txt\",\"a+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext.write(\"This my second attempt in writing a text \\n \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext.seek(0)\n",
    "mytext.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"advs.txt\",\"r\") as mynewfile:\n",
    "    myvariable = mynewfile.readlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myvariable"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n",
      "runner----->>runner\n",
      "ran----->>ran\n",
      "run----->>run\n",
      "easily----->>easili\n",
      "fairly----->>fairli\n",
      "fairness----->>fair\n",
      "lovely----->>love\n",
      "noon----->>noon\n",
      "something----->>someth\n",
      "generous----->>gener\n",
      "generously----->>gener\n",
      "genrate----->>genrat\n",
      "generation----->>gener\n"
     ]
    }
   ],
>>>>>>> ca9a7cba51f67ef83b120e66b68307ba926614a6
   "source": [
    "import nltk\n",
    "nltk.download()\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "p_stemmer = PorterStemmer()\n",
    "words = ['runner', 'ran', 'run', 'easily', 'fairly', 'fairness','lovely', 'noon','something', 'generous', 'generously', 'genrate', 'generation']\n",
    "\n",
    "for word in words:\n",
    "    print(word + '----->>' + p_stemmer.stem(word))\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runner------>>runner\n",
      "ran------>>ran\n",
      "run------>>run\n",
      "easily------>>easili\n",
      "fairly------>>fair\n",
      "fairness------>>fair\n",
      "lovely------>>love\n",
      "noon------>>noon\n",
      "something------>>someth\n",
      "generous------>>generous\n",
      "generously------>>generous\n",
      "genrate------>>genrat\n",
      "generation------>>generat\n"
     ]
    }
   ],
>>>>>>> ca9a7cba51f67ef83b120e66b68307ba926614a6
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "s_stemmer = SnowballStemmer(language= 'english')\n",
    "for word in words:\n",
    "    print(word + '------>>' + s_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I \t PRON \t 4690420944186131903 \t I\n",
      "am \t AUX \t 10382539506755952630 \t be\n",
      "a \t DET \t 11901859001352538922 \t a\n",
      "runner \t NOUN \t 12640964157389618806 \t runner\n",
      "and \t CCONJ \t 2283656566040971221 \t and\n",
      "now \t ADV \t 17157488710739566268 \t now\n",
      "I \t PRON \t 4690420944186131903 \t I\n",
      "am \t AUX \t 10382539506755952630 \t be\n",
      "running \t VERB \t 12767647472892411841 \t run\n",
      "now \t ADV \t 17157488710739566268 \t now\n",
      "and \t CCONJ \t 2283656566040971221 \t and\n",
      "I \t PRON \t 4690420944186131903 \t I\n",
      "love \t VERB \t 3702023516439754181 \t love\n",
      "to \t PART \t 3791531372978436496 \t to\n",
      "win \t VERB \t 471204509717844521 \t win\n",
      "a \t DET \t 11901859001352538922 \t a\n",
      "race \t NOUN \t 8048469955494714898 \t race\n",
      "and \t CCONJ \t 2283656566040971221 \t and\n",
      "as \t SCONJ \t 7437575085468336610 \t as\n",
      "I \t PRON \t 4690420944186131903 \t I\n",
      "ran \t VERB \t 12767647472892411841 \t run\n",
      "I \t PRON \t 4690420944186131903 \t I\n",
      "did \t VERB \t 2158845516055552166 \t do\n",
      "it \t PRON \t 10239237003504588839 \t it\n"
     ]
    }
   ],
>>>>>>> ca9a7cba51f67ef83b120e66b68307ba926614a6
   "source": [
    "import spacy\n",
    "spacy.prefer_gpu()\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "txt = nlp(u\"I am a runner and now I am running now and I love to win a race and as I ran I did it\")\n",
    "for cha in txt:\n",
    "    print(cha.text , '\\t', cha.pos_, '\\t', cha.lemma, '\\t', cha.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "from spacy.matcher import Matcher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'Guru99', 'You', 'have', 'build', 'a', 'very', 'good', 'site', 'and', 'I', 'love', 'visiting', 'your', 'site']\n"
     ]
    }
   ],
>>>>>>> ca9a7cba51f67ef83b120e66b68307ba926614a6
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "filterdText=tokenizer.tokenize('Hello Guru99, You have build a very good site and I love visiting your site.')\n",
    "print(filterdText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.9.7"
=======
   "version": "3.8.10"
>>>>>>> ca9a7cba51f67ef83b120e66b68307ba926614a6
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
